{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada463ac-bbc6-48c1-9dc3-4257fe997cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2023/6/9 上午\n",
    "# @Author  : 东光太狼 游六一\n",
    "# @Content : 预训练语言模型入门系列笔记（一）\n",
    "# 该系列笔记将介绍基于transformer的预训练语言模型，使用该模型解决现实NLP任务。\n",
    "# （一）环境搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e071c-6798-4caa-886b-08a14a5faafb",
   "metadata": {},
   "source": [
    "## 1. 搭建编程环境\n",
    "目前学界业界主流使用python来进行机器学习任务，根据硬件设施条件，可以选择不同的环境搭建方法。\n",
    "1. 本地主机  \n",
    "本地安装Anaconda或者Miniconda  \n",
    "优点：免费，锻炼自己动手能力和耐心  \n",
    "缺点：环境、框架自己搭建和适配（时间成本高，往往搞得自己崩溃）；  \n",
    "本地CPU和GPU性能有限且拓展性差，训练期间本地网络可能不稳定\n",
    "\n",
    "2. 算力平台  \n",
    "平台一：https://www.autodl.com/home  \n",
    "平台二：https://gpushare.com  \n",
    "优点：环境和框架搭建完善，无需手动安装pytorch；  \n",
    "提供GPU和CPU且可拓展性强，适合大规模部署和个人使用  \n",
    "缺点：有一定费用，需要向平台传输数据费时间  \n",
    "\n",
    "3. 在线环境  \n",
    "Google Colab  \n",
    "优点：环境和框架搭建完善，无需费劲安装torch，有些提供GPU；  \n",
    "缺点：免费额度有限，配置较低，不适用大规模数据训练，需要安全上网  \n",
    "\n",
    "最后，该系列笔记均以jupyternotebook形式提供，上述三种本地Anaconda、算力平台、Google Colab中均可以打开该类型文件(.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930f9bd-65f2-4e19-889c-ca99c89867ae",
   "metadata": {},
   "source": [
    "## 2. 深度学习框架\n",
    "深度学习框架有很多，选择pytorch！pytorch！pytorch！\n",
    "1. 学界主流，大多数AI论文的深度学习框架，能够满足语言、文本、音频大多数任务\n",
    "2. 为了适配GPU，需要下载对应版本的pytorch-cuda（本地主机很麻烦，不建议自己适配）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f32125-54c8-477a-815b-cfca6eca2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4713e-25,  4.5887e-41, -7.4800e-25],\n",
      "        [ 3.0770e-41,  7.1041e-25,  3.0770e-41],\n",
      "        [ 6.7604e-25,  3.0770e-41,  4.4842e-44],\n",
      "        [ 0.0000e+00,  6.7262e-44,  0.0000e+00],\n",
      "        [ 6.7997e-25,  3.0770e-41,  2.1891e-27]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#安装torch相关包\n",
    "#!conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia\n",
    "#测试torch是否安装成功\n",
    "import torch\n",
    "x = torch.empty(5,3)\n",
    "print(x)\n",
    "#测试能否调用GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66456831-854c-47ee-a367-2b5ea9827ee4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 深度学习开发包\n",
    "1. Transformers是自然语言处理任务常用的模型，是HuggingFace开源的机器学习库。\n",
    "项目组安装Transformers后，可以下载和使用众多开源的中文预训练模型，有助于快速训练所需模型\n",
    "2. small-text是一个模块化的python库，它为文本分类和多标签任务提供了主动学习方法。\n",
    "它集成了PyTorch和transformers，使得python生态系统可以轻松访问最先进的主动学习。\n",
    "通过small-text实现模型的部署，并通过其内置的主动学习算法进一步优化模型，达到更好的分类效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0d4f5b-a6d7-48f6-b914-ee88beb0f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/17/aa/a89864288afe45abe1ab79f002140a20348140e86836d96096d8f8a3bac0/transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 43.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.5.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/fa/33/acfd230f5c3e7d19bfae949dca45c230fbf1d4d6f62a0b2365caac17c37a/tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 39.4 MB/s eta 0:00:01      | 4.2 MB 39.4 MB/s eta 0:00:014 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Collecting transformers\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/e8/b5/ddb16f9de207e6571ab7cc5db0cc538fa2d6d91cf024565496462af4c1ce/transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 33.6 MB/s eta 0:00:013.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/45/e4/4914b11df70954d95a7c36b74bf9010c8594fcec960471479449b0deb4f7/transformers-4.29.0-py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 43.1 MB/s eta 0:00:01     |████████████████████████████▍   | 6.3 MB 43.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/9e/6b/fdcd53aeee771a868c4187f0955116894a2b1e82d73fb5990c2ef63afc18/filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.22.4)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/df/90/5ad98abead047169f4f86bc67e99020c841d71c9c6bd202e04af71e70e53/huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 34.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Installing collected packages: filelock, tokenizers, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.11.0 huggingface-hub-0.13.4 tokenizers-0.13.2 transformers-4.29.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b86db48c6d4b2ead1b4e70634dfc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/849 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dc2673c5b24862926b591fefd584b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#安装transfromers\n",
    "!pip install transformers\n",
    "#调用预训练模型mengzi-bert-base，用于后续任务\n",
    "from transformers import AutoTokenizer\n",
    "transformer_model_name = \"Langboat/mengzi-bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    transformer_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05c8a82b-6b74-49e1-8d73-1a3dab3493e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting small_text\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/09/00/2c766b4f301282b84ee5a2fbe4e80abb3a957ca64208239861d2cb8110bc/small_text-1.3.0-py3-none-any.whl (202 kB)\n",
      "\u001b[K     |████████████████████████████████| 202 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /root/miniconda3/lib/python3.8/site-packages (from small_text) (1.9.3)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from small_text) (21.3)\n",
      "Collecting scikit-learn>=0.24.1\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/f0/95/0ea0a2412e33080a47ec02802210c008a7a540471581c95145f030d304b4/scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/12/ff/3b1a8f5d59600393506c64fa14d13afdfe6fe79ed65a18d64026fe9f8356/dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 4.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from small_text) (4.61.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /root/miniconda3/lib/python3.8/site-packages (from small_text) (1.22.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.24.1->small_text) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging->small_text) (3.0.9)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, dill, small-text\n",
      "Successfully installed dill-0.3.5.1 scikit-learn-1.2.1 small-text-1.3.0 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#安装small_text\n",
    "!pip install small_text\n",
    "#调用常用模块\n",
    "from small_text import TransformersDataset\n",
    "from small_text import TransformerModelArguments\n",
    "from small_text import TransformerBasedClassificationFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a2c52-70a9-464e-8278-d40f57e8252e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
